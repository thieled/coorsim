% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/05_generate_community_labels.R
\name{label_communities}
\alias{label_communities}
\title{Label Communities Using a Local LLM}
\usage{
label_communities(
  groups_data,
  max_n_per_slice = 10,
  min_chars = 1,
  max_chars = 1000,
  min_share = NULL,
  model = "llama3.2:3b",
  retries = 3,
  retry_trunc = 4000,
  seed = 42,
  temp = 0,
  prompt = NULL,
  system = NULL,
  system_slices = NULL,
  example = NULL,
  example_slices = NULL,
  answer = NULL,
  answer_slices = NULL,
  schema = NULL,
  verbose = TRUE
)
}
\arguments{
\item{groups_data}{A list containing at least a \code{user_labels} element,
typically produced by [sample_user_text()]. This element must include community membership
and sampled post text for each user.}

\item{max_n_per_slice}{Integer. Maximum number of users per slice when splitting large
communities. Default is \code{10}.}

\item{min_chars}{Integer. Minimum character length required for a valid slice input.
Default is \code{1}.}

\item{max_chars}{Integer. Maximum allowed character length per slice (longer input will be truncated).
Default is \code{1000}.}

\item{min_share}{Optional numeric. Minimum cumulative posting share (\code{user_share_comm})
per slice. Default is \code{NULL} (no filter).}

\item{model}{Character string. The local LLM model to query via Ollama
(e.g., \code{"llama3.2:3b"}). Default is \code{"llama3.2:3b"}.}

\item{retries}{Integer. Maximum number of re-query attempts for invalid or unparseable
JSON responses. Default is \code{3}.}

\item{retry_trunc}{Integer. Character limit for truncating text inputs in retry rounds.
Default is \code{4000}.}

\item{seed}{Integer. Random seed for reproducibility. Default is \code{42}.}

\item{temp}{Numeric. Sampling temperature for model generation
(\code{0} = deterministic). Default is \code{0.0}.}

\item{prompt}{Character. User-level prompt text used to instruct the model when labeling
communities (overrides internal \code{prompts$prompt_comm}). Optional.}

\item{system}{Character. System-level instruction guiding the model’s behavior
(overrides internal \code{prompts$system_comm}). Optional.}

\item{system_slices}{Character. Optional override for \code{prompts$system_comm_slices},
used for the aggregation step that combines slice-level labels into one community summary.}

\item{example}{Character vector containing few-shot example inputs for community-level labeling.
Defaults to \code{examples$example_comm_text}.}

\item{example_slices}{Character vector containing few-shot example inputs for aggregated
slice-level labeling. Defaults to \code{examples$example_comm_slices_text}.}

\item{answer}{Character vector of corresponding example model outputs for community-level labeling.
Defaults to \code{examples$example_comm_answer}.}

\item{answer_slices}{Character vector of example outputs for aggregated slice-level labeling.
Defaults to \code{examples$example_comm_slices_answer}.}

\item{schema}{Optional JSON-like list defining the expected structured output format.
Defaults to \code{schemata$schema_comm}.}

\item{verbose}{Logical. Whether to print progress messages, retry information,
and aggregation updates. Default is \code{TRUE}.}
}
\value{
The same \code{groups_data} list, updated with a new \code{community_labels} element.
This is a \pkg{data.table} with one row per labeled community containing:
\describe{
  \item{\code{community}}{Community identifier.}
  \item{\code{label}}{LLM-generated label for the community.}
  \item{\code{description}}{Concise LLM-generated summary of the community’s tone, style, and main topics.}
  \item{\code{lang}}{Predominant language inferred by the model.}
  \item{\code{topic_1–topic_5}}{Up to five thematic categories assigned by the model.}
  \item{\code{named_entity_1–named_entity_5}, \code{sentiment_1–sentiment_5}}{Named entities and associated sentiments.}
  \item{\code{pattern_1–pattern_3}}{Recurring emojis, slogans, or stylistic markers.}
  \item{\code{incivility}}{Whether the community often uses uncivil or offensive language.}
  \item{\code{elaborate}}{Average linguistic elaboration level ("simple", "moderate", or "elaborate").}
  \item{\code{confidence}}{Model-estimated confidence score between 0 and 1.}
  \item{\code{text}}{Input text provided to the model (either slice or aggregated JSON).}
  \item{\code{is_valid_json}}{Logical flag indicating successful JSON validation.}
  \item{\code{model}, \code{model_queried_at}, \code{model_total_duration}}{Metadata about the model run.}
}
}
\description{
This function uses a locally hosted large language model (LLM) via the \pkg{rollama} interface
to generate structured labels and descriptive summaries for user communities. It first labels
each community (or, if large, its individual slices) based on user-level annotations and text,
then optionally aggregates slice-level results in a second LLM pass to produce one coherent
community-level label and description.
}
\details{
If malformed or incomplete JSON responses are returned, the function retries the query up to
a user-specified number of attempts. It supports both single-slice and multi-slice processing,
automatically detecting and aggregating communities that have been split during preprocessing.


The function executes in two main stages:
\enumerate{
  \item \strong{Slice-level labeling:} If a community exceeds \code{max_n_per_slice} users, it is divided
  into smaller slices using [slice_community_text()]. Each slice is labeled independently by the LLM.
  \item \strong{Community-level aggregation:} For multi-slice communities, the slice-level labels and
  descriptions are combined into a JSON array and passed to the model again with
  \code{system_comm_slices} to generate a single coherent label and summary.
}

JSON responses are validated using \pkg{jsonlite}; malformed responses trigger retries with truncated text
up to \code{retries} times. The function expects a locally running Ollama instance with the specified
model available. Verify setup using [rollama::ping_ollama()].
}
\seealso{
[sample_user_text()], [slice_community_text()], [rollama::query()], [rollama::make_query()], [jsonlite::fromJSON()]
}
